{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python 3.6.0\n",
    "# tensorflow 1.1.0\n",
    "# Keras 2.0.4\n",
    "\n",
    "import os\n",
    "import os.path as path\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.tools import freeze_graph\n",
    "from tensorflow.python.tools import optimize_for_inference_lib\n",
    "\n",
    "MODEL_NAME = 'mnist_convnet'\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    y_train = keras.utils.to_categorical(y_train, 10)\n",
    "    y_test = keras.utils.to_categorical(y_test, 10)\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    \n",
    "    \n",
    "  \n",
    "    model = Sequential ()\n",
    "\n",
    "\n",
    "    model.add(Conv2D(32 , kernel_size=(5,5), strides = (1,1) ,activation = 'relu' , input_shape  = [28,28,1] ))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2) , strides=(2,2)))\n",
    "\n",
    "    model . add(Conv2D(64 , (5,5) ,activation = 'relu' ))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "  \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1000 , activation='relu'))\n",
    "    model.add(Dense(10 , activation = 'softmax'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def train(model, x_train, y_train, x_test, y_test):\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, \\\n",
    "                  optimizer=keras.optimizers.Adadelta(), \\\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(x_train, y_train, \\\n",
    "              batch_size=BATCH_SIZE, \\\n",
    "              epochs=EPOCHS, \\\n",
    "              verbose=1, \\\n",
    "              validation_data=(x_test, y_test))\n",
    "\n",
    "\n",
    "def export_model(saver, model, input_node_names, output_node_name):\n",
    "    tf.train.write_graph(K.get_session().graph_def, 'out', \\\n",
    "        MODEL_NAME + '_graph.pbtxt')\n",
    "\n",
    "    saver.save(K.get_session(), 'out/' + MODEL_NAME + '.chkp')\n",
    "\n",
    "    freeze_graph.freeze_graph('out/' + MODEL_NAME + '_graph.pbtxt', None, \\\n",
    "        False, 'out/' + MODEL_NAME + '.chkp', output_node_name, \\\n",
    "        \"save/restore_all\", \"save/Const:0\", \\\n",
    "        'out/frozen_' + MODEL_NAME + '.pb', True, \"\")\n",
    "\n",
    "    input_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.Open('out/frozen_' + MODEL_NAME + '.pb', \"rb\") as f:\n",
    "        input_graph_def.ParseFromString(f.read())\n",
    "\n",
    "    output_graph_def = optimize_for_inference_lib.optimize_for_inference(\n",
    "            input_graph_def, input_node_names, [output_node_name],\n",
    "            tf.float32.as_datatype_enum)\n",
    "\n",
    "    with tf.gfile.FastGFile('out/opt_' + MODEL_NAME + '.pb', \"wb\") as f:\n",
    "        f.write(output_graph_def.SerializeToString())\n",
    "\n",
    "    print(\"graph saved!\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    if not path.exists('out'):\n",
    "        os.mkdir('out')\n",
    "\n",
    "    x_train, y_train, x_test, y_test = load_data()\n",
    "\n",
    "    model = build_model()\n",
    "\n",
    "    train(model, x_train, y_train, x_test, y_test)\n",
    "\n",
    "    export_model(tf.train.Saver(), model, [\"conv2d_1_input\"], \"dense_2/Softmax\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import graph_io\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "weight_file_path = 'mnist.h5'\n",
    "net_model = load_model(weight_file_path)\n",
    "sess = K.get_session()\n",
    "out_nodes = []\n",
    "out_prefix=\"output_\"\n",
    "\n",
    "for i in range(len(net_model.outputs)):\n",
    "    out_nodes.append(out_prefix + str(i + 1))\n",
    "    tf.identity(net_model.output[i], out_prefix + str(i + 1))\n",
    "constant_graph = graph_util.convert_variables_to_constants(sess, sess.graph.as_graph_def(), out_nodes)\n",
    "graph_io.write_graph(constant_graph, '', 'output.pb', as_text=False)\n",
    "print('saved the constant graph (ready for inference) at: ', osp.join('', 'output.pb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
